{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO02A4WAAd6+rtTAe5pJQMQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Exercises & Extra-curriculum"],"metadata":{"id":"8wACtiLUfjnq"}},{"cell_type":"markdown","source":["## 1. Turn the code to get the data (from section 1. Get Data above) into a Python script, such as `get_data.py`\n","- When you run the script using `python get_data.py` it should check if the data already exists and skip downloading if it does.\n","- If the data download is successful, you should be able to access the `pizza_steak_sushi` images from the data directory."],"metadata":{"id":"6RevZF8vfml1"}},{"cell_type":"code","source":["import os\n","\n","os.makedirs('going_modular', exist_ok=True)"],"metadata":{"id":"8n3ZRoMPf-IT","executionInfo":{"status":"ok","timestamp":1685414379096,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fy2W1-h4fe9h","executionInfo":{"status":"ok","timestamp":1685414379552,"user_tz":-540,"elapsed":463,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"93a408b4-11bc-4ece-8cce-4ade93153adf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/get_data.py\n"]}],"source":["%%writefile going_modular/get_data.py\n","\n","# Import libraries\n","import os\n","import requests\n","import zipfile\n","import torch\n","import torchvision\n","from torchvision import datasets\n","from pathlib import Path\n","\n","# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"pizza_steak_sushi\"\n","zipfile_path = data_path / \"pizza_steak_sushi.zip\"\n","\n","# If the image folder doesn't exist, download it and prepare it\n","if image_path.is_dir():\n","    print(f\"{image_path} already exists\")\n","else:\n","    print(f\"Did not find {image_path} directory, creating one\")\n","    image_path.mkdir(parents=True, exist_ok=True)\n","\n","# Download data\n","with open(zipfile_path, \"wb\") as f:\n","    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","    print(\"Downloading data\")\n","    f.write(request.content)\n","\n","# Unzip data\n","with zipfile.ZipFile(zipfile_path, \"r\") as zip_ref:\n","    print(f\"Unzipping data\")\n","    zip_ref.extractall(image_path)\n","\n","# Remove zip file\n","os.remove(zipfile_path)\n","\n","# To get the original dataset from torchvision.datasets\n","# food101_data_train = torchvision.datasets.Food101(root=image_path, split='train', download=True)\n","# food101_data_test = datasets.Food101(root=image_path, split='test', download=True)"]},{"cell_type":"code","source":["!python going_modular/get_data.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8NW7eRS-qtJ","executionInfo":{"status":"ok","timestamp":1685414392568,"user_tz":-540,"elapsed":13026,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"7843fc7d-bbe0-47cc-a82c-e71187cebeaa"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Did not find data/pizza_steak_sushi directory, creating one\n","Downloading data\n","Unzipping data\n"]}]},{"cell_type":"markdown","source":["## 2. Use [Python's `argparse` module](https://docs.python.org/3/library/argparse.html) to be able to send the `train.py` custom hyperparameter values for training procedures.\n","- Add an argument for using a different:\n","    - Training/testing directory\n","    - Learning rate\n","    - Batch size\n","    - Number of epochs to train for\n","    - Number of hidden units in the TinyVGG model\n","- Keep the default values for each of the above arguments as what they already are (as in notebook 05).\n","- For example, you should be able to run something similar to the following line to train a TinyVGG model with a learning rate of 0.003 and a batch size of 64 for 20 epochs: `python train.py --learning_rate 0.003 --batch_size 64 --num_epochs 20`\n","- **Note:** Since `train.py` leverages the other scripts we created in section 05, such as, `model_builder.py`, `utils.py`, and `engine.py`, you'll have to make sure they're available to use too. You can find these in the [`going_modular` folder on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/going_modular/going_modular)"],"metadata":{"id":"oy4z1X8zjb8O"}},{"cell_type":"code","source":["%%writefile going_modular/data_setup.py\n","\"\"\"\n","Contains functionality for creating PyTorch DataLoader\n","for image classification data\n","\"\"\"\n","import os\n","\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","NUM_WORKERS = os.cpu_count()\n","\n","def create_dataloaders(\n","    train_dir: str,\n","    test_dir: str,\n","    transform: transforms.Compose,\n","    batch_size: int,\n","    num_workers: int=NUM_WORKERS\n","):\n","    \"\"\"\n","    Creates training and testing dataloaders\n","\n","    Takes in training and testing directory paths and turns them\n","    into PyTorch Dataset and then into PyTorch DataLoader\n","\n","    Args:\n","        train_dir: Path to training directory\n","        test_dir: Path to testing directory\n","        transform: torchvision transforms to perform on training and testing data\n","        batch_size: Number of samples per batch in each of the DataLoader\n","        num_workers: An integer for number of workers per DataLoader\n","    \n","    Returns:\n","        A tuple of (train_dataloader, test_dataloader, class_names)\n","        where class_names is a list of the target classes\n","        \n","        Example usage:\n","            train_dataloader, test_dataloader, class_names = \\\n","                create_dataloaders(train_dir=path/to/train_dir,\n","                                   test_dir=path/to/test_dir,\n","                                   transform=some_transform,\n","                                   batch_size=32,\n","                                   num_workers=2)\n","    \"\"\"\n","    # Use ImageFolder to create datasets\n","    train_data = datasets.ImageFolder(train_dir, transform=transform)\n","    test_data = datasets.ImageFolder(test_dir, transform=transform)\n","\n","    # Get class names\n","    class_names = train_data.classes\n","\n","    # Turn images into dataloaders\n","    train_dataloader = DataLoader(dataset=train_data,\n","                                  batch_size=batch_size,\n","                                  shuffle=True,\n","                                  num_workers=num_workers,\n","                                  pin_memory=True)\n","    test_dataloader = DataLoader(dataset=test_data,\n","                                 batch_size=batch_size,\n","                                 shuffle=True,\n","                                 num_workers=num_workers,\n","                                 pin_memory=True)\n","    \n","    return train_dataloader, test_dataloader, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jqlV5V33oal","executionInfo":{"status":"ok","timestamp":1685414392569,"user_tz":-540,"elapsed":34,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"0d2500e6-b1ab-431d-ba2e-0831cb65909e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/data_setup.py\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/model_builder.py\n","\"\"\"\n","Contains PyTorch model code to instantiate a TinyVGG model.\n","\"\"\"\n","import torch\n","from torch import nn \n","\n","class TinyVGG(nn.Module):\n","  \"\"\"Creates the TinyVGG architecture.\n","\n","  Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n","  See the original architecture here: https://poloclub.github.io/cnn-explainer/\n","\n","  Args:\n","    input_shape: An integer indicating number of input channels.\n","    hidden_units: An integer indicating number of hidden units between layers.\n","    output_shape: An integer indicating number of output units.\n","  \"\"\"\n","  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n","      super().__init__()\n","      self.conv_block_1 = nn.Sequential(\n","          nn.Conv2d(in_channels=input_shape, \n","                    out_channels=hidden_units, \n","                    kernel_size=3, \n","                    stride=1, \n","                    padding=0),  \n","          nn.ReLU(),\n","          nn.Conv2d(in_channels=hidden_units, \n","                    out_channels=hidden_units,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2,\n","                        stride=2)\n","      )\n","      self.conv_block_2 = nn.Sequential(\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(2)\n","      )\n","      self.classifier = nn.Sequential(\n","          nn.Flatten(),\n","          # Where did this in_features shape come from? \n","          # It's because each layer of our network compresses and changes the shape of our inputs data.\n","          nn.Linear(in_features=hidden_units*13*13,\n","                    out_features=output_shape)\n","      )\n","\n","  def forward(self, x: torch.Tensor):\n","      x = self.conv_block_1(x)\n","      x = self.conv_block_2(x)\n","      x = self.classifier(x)\n","      return x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1TH2b2D85a0u","executionInfo":{"status":"ok","timestamp":1685414392570,"user_tz":-540,"elapsed":30,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"1b13da32-9e97-4f39-91e5-e6b153118130"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/model_builder.py\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/engine.py\n","\"\"\"\n","Contains functions for training and testing a PyTorch model\n","\"\"\"\n","import torch\n","\n","from tqdm.auto import tqdm\n","from typing import Dict, List, Tuple\n","\n","def train_step(model: torch.nn.Module, \n","               dataloader: torch.utils.data.DataLoader, \n","               loss_fn: torch.nn.Module, \n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> Tuple[float, float]:\n","    \"\"\"Trains a PyTorch model for a single epoch.\n","\n","    Turns a target PyTorch model to training mode and then\n","    runs through all of the required training steps (forward\n","    pass, loss calculation, optimizer step).\n","\n","    Args:\n","    model: A PyTorch model to be trained.\n","    dataloader: A DataLoader instance for the model to be trained on.\n","    loss_fn: A PyTorch loss function to minimize.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","    Returns:\n","    A tuple of training loss and training accuracy metrics.\n","    In the form (train_loss, train_accuracy). For example:\n","\n","    (0.1112, 0.8743)\n","    \"\"\"\n","    # Put model in train mode\n","    model.train()\n","\n","    # Setup train loss and train accuracy values\n","    train_loss, train_acc = 0, 0\n","\n","    # Loop through data loader data batches\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Send data to target device\n","        X, y = X.to(device), y.to(device)\n","\n","        # 1. Forward pass\n","        y_pred = model(X)\n","\n","        # 2. Calculate  and accumulate loss\n","        loss = loss_fn(y_pred, y)\n","        train_loss += loss.item() \n","\n","        # 3. Optimizer zero grad\n","        optimizer.zero_grad()\n","\n","        # 4. Loss backward\n","        loss.backward()\n","\n","        # 5. Optimizer step\n","        optimizer.step()\n","\n","        # Calculate and accumulate accuracy metric across all batches\n","        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n","        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n","\n","    # Adjust metrics to get average loss and accuracy\n","    train_loss = train_loss / len(dataloader)\n","    train_acc = train_acc / len(dataloader)\n","    return train_loss, train_acc\n","\n","def test_step(model: torch.nn.Module, \n","              dataloader: torch.utils.data.DataLoader, \n","              loss_fn: torch.nn.Module,\n","              device: torch.device) -> Tuple[float, float]:\n","    \"\"\"Tests a PyTorch model for a single epoch.\n","\n","    Turns a target PyTorch model to \"eval\" mode and then performs\n","    a forward pass on a testing dataset.\n","\n","    Args:\n","    model: A PyTorch model to be tested.\n","    dataloader: A DataLoader instance for the model to be tested on.\n","    loss_fn: A PyTorch loss function to calculate loss on the test data.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","    Returns:\n","    A tuple of testing loss and testing accuracy metrics.\n","    In the form (test_loss, test_accuracy). For example:\n","\n","    (0.0223, 0.8985)\n","    \"\"\"\n","    # Put model in eval mode\n","    model.eval() \n","\n","    # Setup test loss and test accuracy values\n","    test_loss, test_acc = 0, 0\n","\n","    # Turn on inference context manager\n","    with torch.inference_mode():\n","        # Loop through DataLoader batches\n","        for batch, (X, y) in enumerate(dataloader):\n","            # Send data to target device\n","            X, y = X.to(device), y.to(device)\n","\n","            # 1. Forward pass\n","            test_pred_logits = model(X)\n","\n","            # 2. Calculate and accumulate loss\n","            loss = loss_fn(test_pred_logits, y)\n","            test_loss += loss.item()\n","\n","            # Calculate and accumulate accuracy\n","            test_pred_labels = test_pred_logits.argmax(dim=1)\n","            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n","\n","    # Adjust metrics to get average loss and accuracy\n","    test_loss = test_loss / len(dataloader)\n","    test_acc = test_acc / len(dataloader)\n","    return test_loss, test_acc\n","\n","def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","          test_dataloader: torch.utils.data.DataLoader,\n","          loss_fn: torch.nn.Module,\n","          optimizer: torch.optim.Optimizer,\n","          epochs: int,\n","          device: torch.device) -> Dict[str, List]:\n","    \"\"\"Trains and tests a PyTorch model.\n","\n","    Passes a target PyTorch models through train_step() and test_step()\n","    functions for a number of epochs, training and testing the model\n","    in the same epoch loop.\n","\n","    Calculates, prints and stores evaluation metrics throughout.\n","\n","    Args:\n","    model: A PyTorch model to be trained and tested.\n","    train_dataloader: A DataLoader instance for the model to be trained on.\n","    test_dataloader: A DataLoader instance for the model to be tested on.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n","    epochs: An integer indicating how many epochs to train for.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","    Returns:\n","    A dictionary of training and testing loss as well as training and\n","    testing accuracy metrics. Each metric has a value in a list for \n","    each epoch.\n","    In the form: {train_loss: [...],\n","                    train_acc: [...],\n","                    test_loss: [...],\n","                    test_acc: [...]} \n","    For example if training for epochs=2: \n","                    {train_loss: [2.0616, 1.0537],\n","                    train_acc: [0.3945, 0.3945],\n","                    test_loss: [1.2641, 1.5706],\n","                    test_acc: [0.3400, 0.2973]} \n","    \"\"\"\n","    # Create empty results dictionary\n","    results = {\"train_loss\": [],\n","               \"train_acc\": [],\n","               \"test_loss\": [],\n","               \"test_acc\": []}\n","\n","    # Loop through training and testing steps for a number of epochs\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model=model,\n","                                           dataloader=train_dataloader,\n","                                           loss_fn=loss_fn,\n","                                           optimizer=optimizer,\n","                                           device=device)\n","        test_loss, test_acc = test_step(model=model,\n","                                        dataloader=test_dataloader,\n","                                        loss_fn=loss_fn,\n","                                        device=device)\n","        \n","        # Print out what's happening\n","        print(f\"Epoch: {epoch} | Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n","\n","        # Update results dictionary\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss)\n","        results[\"test_acc\"].append(test_acc)\n","\n","    # Return the filled results at the end of the epochs\n","    return results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtOSB5u654zn","executionInfo":{"status":"ok","timestamp":1685414392570,"user_tz":-540,"elapsed":25,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"4f5fb3cb-f944-412b-a578-02cee2977faa"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/engine.py\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/utils.py\n","\"\"\"\n","Contains various utility functions for PyTorch model training and saving.\n","\"\"\"\n","import torch\n","from pathlib import Path\n","\n","def save_model(model: torch.nn.Module,\n","               target_dir: str,\n","               model_name: str):\n","    \"\"\"Saves a PyTorch model to a target directory.\n","\n","    Args:\n","    model: A target PyTorch model to save.\n","    target_dir: A directory for saving the model to.\n","    model_name: A filename for the saved model. Should include\n","        either \".pth\" or \".pt\" as the file extension.\n","\n","    Example usage:\n","    save_model(model=model_0,\n","                target_dir=\"models\",\n","                model_name=\"05_going_modular_tingvgg_model.pth\")\n","    \"\"\"\n","    # Create target directory\n","    target_dir_path = Path(target_dir)\n","    target_dir_path.mkdir(parents=True,\n","                          exist_ok=True)\n","    \n","    # Create model save path\n","    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\")\n","    model_save_path = target_dir_path / model_name\n","\n","    # Save the model state_dict()\n","    print(f\"[INFO] Saving model to: {model_save_path}\")\n","    torch.save(obj=model.state_dict(),\n","               f=model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oUJshppR39oW","executionInfo":{"status":"ok","timestamp":1685414392571,"user_tz":-540,"elapsed":22,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"ec407327-3aef-4ea6-b5be-5cc097340343"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/utils.py\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/train.py\n","\"\"\"\n","Trains a PyTorch image classification model using device-agnostic code.\n","\"\"\"\n","\n","import os\n","import torch\n","import argparse\n","import data_setup, engine, model_builder, utils\n","\n","from torchvision import transforms\n","\n","# Create a parser\n","parser = argparse.ArgumentParser(description=\"Get hyperparameters\")\n","\n","# Get arg for hyperparameters\n","parser.add_argument(\"--epochs\", default=10, type=int, help=\"number of epochs to train the model\")\n","parser.add_argument(\"--batch_size\", default=32, type=int, help=\"number of samples per batch\")\n","parser.add_argument(\"--hidden_units\", default=10, type=int, help=\"number of hidden units in hidden layers\")\n","parser.add_argument(\"--learning_rate\", default=0.001, type=float, help=\"learning rate to train the model\")\n","parser.add_argument(\"--train_dir\", default=\"data/pizza_steak_sushi/train\", type=str, help=\"directory file path to training data\")\n","parser.add_argument(\"--test_dir\", default=\"data/pizza_steak_sushi/test\", type=str, help=\"directory file path to testing data\")\n","\n","# Get our arguments from the parser\n","args = parser.parse_args()\n","\n","# Setup hyperparameters\n","EPOCHS = args.epochs\n","BATCH_SIZE = args.batch_size\n","HIDDEN_UNITS = args.hidden_units\n","LEARNING_RATE = args.learning_rate\n","print(f\"[INFO] Training a model for {EPOCHS} epochs with batch size {BATCH_SIZE} using {HIDDEN_UNITS} hidden units and a learning rate of {LEARNING_RATE}\")\n","\n","# Setup directories\n","train_dir = args.train_dir\n","test_dir = args.test_dir\n","print(f\"[INFO] Training data file path: {train_dir}\")\n","print(f\"[INFO] Testing data file path: {test_dir}\")\n","\n","# Setup target device\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Create transforms\n","data_transform = transforms.Compose([\n","    transforms.Resize(size=(64, 64)),\n","    transforms.ToTensor()\n","])\n","\n","# Create dataloaders using data_setup.py\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n","    train_dir=train_dir,\n","    test_dir=test_dir,\n","    transform=data_transform,\n","    batch_size=BATCH_SIZE\n",")\n","\n","# Create a model using model_builder.py\n","model = model_builder.TinyVGG(\n","    input_shape=3,\n","    hidden_units=HIDDEN_UNITS,\n","    output_shape=len(class_names)\n",").to(device)\n","\n","# Set loss and optimizer\n","loss_fn = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params=model.parameters(),\n","                             lr=LEARNING_RATE)\n","\n","# Start training using engine.py\n","engine.train(model=model,\n","             train_dataloader=train_dataloader,\n","             test_dataloader=test_dataloader,\n","             loss_fn=loss_fn,\n","             optimizer=optimizer,\n","             epochs=EPOCHS,\n","             device=device)\n","\n","# Save the model using utils.py\n","utils.save_model(model=model,\n","                 target_dir=\"models\",\n","                 model_name=\"05_going_modular_tingvgg_model.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3i8oa0r94fPg","executionInfo":{"status":"ok","timestamp":1685414392572,"user_tz":-540,"elapsed":19,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"3b283cff-c5e5-443d-d741-f17516064827"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/train.py\n"]}]},{"cell_type":"code","source":["!python going_modular/train.py --epochs=20 --learning_rate=0.05 --batch_size=64"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpPUcRvThqom","executionInfo":{"status":"ok","timestamp":1685414447117,"user_tz":-540,"elapsed":54560,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"ac9b668a-7e0a-4d8d-8852-f8abc508afcb"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Training a model for 20 epochs with batch size 64 using 10 hidden units and a learning rate of 0.05\n","[INFO] Training data file path: data/pizza_steak_sushi/train\n","[INFO] Testing data file path: data/pizza_steak_sushi/test\n","  0% 0/20 [00:00<?, ?it/s]Epoch: 0 | Train loss: 38.8435 | Train acc: 0.3182 | Test loss: 4.2773 | Test acc: 0.3835\n","  5% 1/20 [00:04<01:21,  4.30s/it]Epoch: 1 | Train loss: 1.9002 | Train acc: 0.3451 | Test loss: 1.1270 | Test acc: 0.2706\n"," 10% 2/20 [00:06<00:55,  3.08s/it]Epoch: 2 | Train loss: 1.0985 | Train acc: 0.2901 | Test loss: 1.1403 | Test acc: 0.2614\n"," 15% 3/20 [00:08<00:45,  2.69s/it]Epoch: 3 | Train loss: 1.1039 | Train acc: 0.3297 | Test loss: 1.1355 | Test acc: 0.2237\n"," 20% 4/20 [00:11<00:42,  2.63s/it]Epoch: 4 | Train loss: 1.1019 | Train acc: 0.3333 | Test loss: 1.1263 | Test acc: 0.1861\n"," 25% 5/20 [00:13<00:37,  2.47s/it]Epoch: 5 | Train loss: 1.1036 | Train acc: 0.3260 | Test loss: 1.1070 | Test acc: 0.3366\n"," 30% 6/20 [00:16<00:38,  2.78s/it]Epoch: 6 | Train loss: 1.1036 | Train acc: 0.3113 | Test loss: 1.1047 | Test acc: 0.3459\n"," 35% 7/20 [00:19<00:34,  2.64s/it]Epoch: 7 | Train loss: 1.0987 | Train acc: 0.3414 | Test loss: 1.1063 | Test acc: 0.3459\n"," 40% 8/20 [00:21<00:30,  2.50s/it]Epoch: 8 | Train loss: 1.0973 | Train acc: 0.3634 | Test loss: 1.0994 | Test acc: 0.3459\n"," 45% 9/20 [00:23<00:26,  2.41s/it]Epoch: 9 | Train loss: 1.0995 | Train acc: 0.3377 | Test loss: 1.1093 | Test acc: 0.1953\n"," 50% 10/20 [00:25<00:23,  2.36s/it]Epoch: 10 | Train loss: 1.0985 | Train acc: 0.3451 | Test loss: 1.0978 | Test acc: 0.3082\n"," 55% 11/20 [00:28<00:22,  2.50s/it]Epoch: 11 | Train loss: 1.0986 | Train acc: 0.3524 | Test loss: 1.0978 | Test acc: 0.2706\n"," 60% 12/20 [00:31<00:20,  2.60s/it]Epoch: 12 | Train loss: 1.1004 | Train acc: 0.3267 | Test loss: 1.0912 | Test acc: 0.4588\n"," 65% 13/20 [00:33<00:17,  2.49s/it]Epoch: 13 | Train loss: 1.0985 | Train acc: 0.3524 | Test loss: 1.1014 | Test acc: 0.2330\n"," 70% 14/20 [00:35<00:14,  2.41s/it]Epoch: 14 | Train loss: 1.0982 | Train acc: 0.3524 | Test loss: 1.0981 | Test acc: 0.4212\n"," 75% 15/20 [00:38<00:11,  2.34s/it]Epoch: 15 | Train loss: 1.0982 | Train acc: 0.3487 | Test loss: 1.1064 | Test acc: 0.2706\n"," 80% 16/20 [00:40<00:09,  2.33s/it]Epoch: 16 | Train loss: 1.0976 | Train acc: 0.3634 | Test loss: 1.1105 | Test acc: 0.2706\n"," 85% 17/20 [00:43<00:07,  2.66s/it]Epoch: 17 | Train loss: 1.0976 | Train acc: 0.3524 | Test loss: 1.0983 | Test acc: 0.3835\n"," 90% 18/20 [00:46<00:05,  2.54s/it]Epoch: 18 | Train loss: 1.0981 | Train acc: 0.3451 | Test loss: 1.1068 | Test acc: 0.3082\n"," 95% 19/20 [00:48<00:02,  2.43s/it]Epoch: 19 | Train loss: 1.1006 | Train acc: 0.3377 | Test loss: 1.1031 | Test acc: 0.3459\n","100% 20/20 [00:50<00:00,  2.53s/it]\n","[INFO] Saving model to: models/05_going_modular_tingvgg_model.pth\n"]}]},{"cell_type":"markdown","source":["## 3. Create a script to predict (such as `predict.py`) on a target image given a file path with a saved model.\n","- For example, you should be able to run the command `python predict.py` `some_image.jpeg` and have a trained PyTorch model predict on the image and return its prediction.\n","- To see example prediction code, check out the [predicting on a custom image section in notebook 04](https://www.learnpytorch.io/04_pytorch_custom_datasets/#113-putting-custom-image-prediction-together-building-a-function)\n","- You may also have to write code to load in a trained model."],"metadata":{"id":"DwKOoTFFrfj6"}},{"cell_type":"code","source":["%%writefile going_modular/predict.py\n","\n","import torch\n","import torchvision\n","import argparse\n","import model_builder\n","\n","# Creating a parser\n","parser = argparse.ArgumentParser()\n","\n","# Get an image path\n","parser.add_argument(\"--image\", help=\"target image to predict on\")\n","\n","# Get a model path\n","parser.add_argument(\"--model_path\", default=\"models/05_going_modular_tingvgg_model.pth\", help=\"target model to use for prediction\")\n","\n","args = parser.parse_args()\n","\n","# Setup class names\n","class_names = [\"pizza\", \"steak\", \"sushi\"]\n","\n","# Setup device\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Get the image path\n","IMG_PATH = args.image\n","print(f\"[INFO] Predicting on {IMG_PATH}\")\n","\n","# Function to load in the model\n","def load_model(filepath=args.model_path):\n","    # Need to use same hyperparameters as the saved model\n","    model = model_builder.TinyVGG(input_shape=3,\n","                                  hidden_units=10,\n","                                  output_shape=3).to(device)\n","    print(f\"[INFO] Loading in model from: {filepath}\")                              \n","    # Load in the saved model state dictionary from file                                  \n","    model.load_state_dict(torch.load(filepath))\n","\n","    return model\n","\n","# Function to load in model + predict on select image\n","def predict_on_image(image=IMG_PATH, filepath=args.model_path):\n","    # Load the model\n","    model = load_model(filepath)\n","    # Load in the image and turn it into torch.float32 (same type as model)\n","    image = torchvision.io.read_image(str(IMG_PATH)).type(torch.float32)\n","\n","    # Preprocess the image to get it between 0 and 1\n","    image = image / 255.\n","\n","    # Expand to 4 dims to include batch dimension [batch_size, color_channels, height, width]\n","    image = image.unsqueeze(0)\n","\n","    # Resize the image to be on the same size as the model\n","    transform = torchvision.transforms.Resize(size=(64, 64), antialias=True)\n","    image = transform(image)\n","\n","    # Predict on image\n","    model.eval()\n","    with torch.inference_mode():\n","        # Put image to target device\n","        image = image.to(device)\n","\n","        # Get pred logits\n","        pred_logits = model(image)\n","\n","        # Get pred probs\n","        pred_probs = torch.softmax(pred_logits, dim=1)\n","\n","        # Get pred labels\n","        pred_label = torch.argmax(pred_probs, dim=1)\n","        pred_label_class = class_names[pred_label]\n","\n","    print(f\"[INFO] Pred class: {pred_label_class}, Pred prob: {pred_probs.max():.3f}\")\n","\n","# Indicating that when you pass the file, it'll be the main one\n","if __name__==\"__main__\":\n","    predict_on_image()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BYUD5HJgmxjX","executionInfo":{"status":"ok","timestamp":1685414447118,"user_tz":-540,"elapsed":33,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"364fabd5-0b38-4695-ce49-ad05ab242d03"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/predict.py\n"]}]},{"cell_type":"code","source":["!python going_modular/predict.py --image data/pizza_steak_sushi/test/steak/27415.jpg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xy5J8f4mEdcS","executionInfo":{"status":"ok","timestamp":1685414449955,"user_tz":-540,"elapsed":2861,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"d68c0319-9753-4337-c124-aaa3eb47cf1b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Predicting on data/pizza_steak_sushi/test/steak/27415.jpg\n","[INFO] Loading in model from: models/05_going_modular_tingvgg_model.pth\n","[INFO] Pred class: pizza, Pred prob: 0.357\n"]}]}]}